import os
import requests
import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

@dataclass
class AIResponse:
    """AIå“åº”æ•°æ®ç±»"""
    content: str
    usage: Optional[Dict[str, Any]] = None
    model: Optional[str] = None
    error: Optional[str] = None

class OpenRouterClient:
    """OpenRouter APIå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: Optional[str] = None, base_url: str = "https://openrouter.ai/api/v1"):
        self.api_key = api_key or os.getenv('OPENROUTER_API_KEY')
        self.base_url = base_url
        self.headers = {
            'Authorization': f'Bearer {self.api_key}' if self.api_key else '',
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:5000',
            'X-Title': 'AI Notebook'
        }
    
    def chat_completion(self, 
                       messages: List[Dict[str, str]], 
                       model: str = "anthropic/claude-3-haiku",
                       max_tokens: int = 1000,
                       temperature: float = 0.7) -> AIResponse:
        """å‘é€èŠå¤©Completedè¯·æ±‚"""
        
        # å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œè¿”å›æ¨¡æ‹Ÿå“åº”
        if not self.api_key:
            return self._get_mock_response(messages)
        
        try:
            payload = {
                "model": model,
                "messages": messages,
                "max_tokens": max_tokens,
                "temperature": temperature
            }
            
            print(f"[DEBUG] Making API request to: {self.base_url}/chat/completions")
            print(f"[DEBUG] Authorization header: {self.headers.get('Authorization', 'NOT SET')}")
            print(f"[DEBUG] API Key length: {len(self.api_key) if self.api_key else 0}")
            print(f"[DEBUG] Payload model: {payload['model']}")
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            print(f"[DEBUG] Response status: {response.status_code}")
            print(f"[DEBUG] Response text: {response.text[:200]}...")
            
            if response.status_code == 200:
                data = response.json()
                content = data['choices'][0]['message']['content']
                usage = data.get('usage', {})
                
                return AIResponse(
                    content=content,
                    usage=usage,
                    model=model
                )
            else:
                error_msg = f"API Request Failed: {response.status_code} - {response.text}"
                return AIResponse(
                    content="",
                    error=error_msg
                )
                
        except requests.exceptions.RequestException as e:
            return AIResponse(
                content="",
                error=f"Network Request Error: {str(e)}"
            )
        except Exception as e:
            return AIResponse(
                content="",
                error=f"Unknown Error: {str(e)}"
            )
    
    def _get_mock_response(self, messages: List[Dict[str, str]]) -> AIResponse:
        """è·å–æ¨¡æ‹ŸAIå“åº”ï¼ˆå½“æ²¡æœ‰APIå¯†é’¥æ—¶ä½¿ç”¨ï¼‰"""
        
        last_message = messages[-1]['content'].lower() if messages else ""
        
        # æ ¹æ®æ¶ˆæ¯å†…å®¹è¿”å›ä¸åŒçš„æ¨¡æ‹Ÿå“åº”
        if "é¡¹ç›®è§„åˆ’" in last_message or "project planning" in last_message:
            content = self._get_project_planning_response()
        elif "ä»»åŠ¡å¢å¼º" in last_message or "task enhance" in last_message:
            content = self._get_task_enhancement_response()
        elif "åˆ†è§£" in last_message or "breakdown" in last_message:
            content = self._get_task_breakdown_response()
        else:
            content = self._get_general_response()
        
        return AIResponse(
            content=content,
            model="mock-model",
            usage={"prompt_tokens": 100, "completion_tokens": 200, "total_tokens": 300}
        )
    
    def _get_project_planning_response(self) -> str:
        """é¡¹ç›®è§„åˆ’æ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "project_analysis": {
                "complexity": "ä¸­ç­‰",
                "estimated_duration": "2-4å‘¨",
                "key_challenges": [
                    "éœ€æ±‚åˆ†æå’Œæ¶æ„è®¾è®¡",
                    "æŠ€æœ¯é€‰å‹å’Œç¯å¢ƒæ­å»º",
                    "æ ¸å¿ƒåŠŸèƒ½å¼€å‘å’Œæµ‹è¯•",
                    "ç”¨æˆ·ä½“éªŒä¼˜åŒ–"
                ]
            },
            "suggested_tasks": [
                {
                    "title": "éœ€æ±‚åˆ†æå’ŒæŠ€æœ¯è°ƒç ”",
                    "description": "è¯¦ç»†åˆ†æé¡¹ç›®éœ€æ±‚ï¼Œè°ƒç ”ç›¸å…³æŠ€æœ¯æ–¹æ¡ˆï¼Œåˆ¶å®šæŠ€æœ¯æ¶æ„",
                    "priority": "high",
                    "estimated_time": "3-5å¤©",
                    "dependencies": []
                },
                {
                    "title": "ç¯å¢ƒæ­å»ºå’ŒåŸºç¡€æ¡†æ¶",
                    "description": "æ­å»ºå¼€å‘ç¯å¢ƒï¼Œåˆ›å»ºé¡¹ç›®åŸºç¡€æ¡†æ¶å’Œç›®å½•ç»“æ„",
                    "priority": "high",
                    "estimated_time": "1-2å¤©",
                    "dependencies": ["éœ€æ±‚åˆ†æå’ŒæŠ€æœ¯è°ƒç ”"]
                },
                {
                    "title": "æ ¸å¿ƒåŠŸèƒ½æ¨¡å—å¼€å‘",
                    "description": "å¼€å‘é¡¹ç›®çš„æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼Œå®ç°ä¸»è¦ä¸šåŠ¡é€»è¾‘",
                    "priority": "high",
                    "estimated_time": "1-2å‘¨",
                    "dependencies": ["ç¯å¢ƒæ­å»ºå’ŒåŸºç¡€æ¡†æ¶"]
                },
                {
                    "title": "ç”¨æˆ·ç•Œé¢è®¾è®¡å’Œå®ç°",
                    "description": "è®¾è®¡ç”¨æˆ·ç•Œé¢ï¼Œå®ç°å‰ç«¯äº¤äº’åŠŸèƒ½",
                    "priority": "medium",
                    "estimated_time": "3-5å¤©",
                    "dependencies": ["æ ¸å¿ƒåŠŸèƒ½æ¨¡å—å¼€å‘"]
                },
                {
                    "title": "æµ‹è¯•å’Œä¼˜åŒ–",
                    "description": "è¿›è¡ŒåŠŸèƒ½æµ‹è¯•ã€æ€§èƒ½ä¼˜åŒ–å’ŒbugRepair",
                    "priority": "medium",
                    "estimated_time": "2-3å¤©",
                    "dependencies": ["ç”¨æˆ·ç•Œé¢è®¾è®¡å’Œå®ç°"]
                }
            ],
            "milestones": [
                {
                    "name": "é¡¹ç›®å¯åŠ¨",
                    "description": "Completedéœ€æ±‚åˆ†æå’Œç¯å¢ƒæ­å»º",
                    "target_date": "ç¬¬1å‘¨"
                },
                {
                    "name": "æ ¸å¿ƒåŠŸèƒ½Completed",
                    "description": "ä¸»è¦åŠŸèƒ½æ¨¡å—å¼€å‘Completed",
                    "target_date": "ç¬¬3å‘¨"
                },
                {
                    "name": "é¡¹ç›®äº¤ä»˜",
                    "description": "Completedæµ‹è¯•å’Œä¼˜åŒ–ï¼Œé¡¹ç›®å¯äº¤ä»˜",
                    "target_date": "ç¬¬4å‘¨"
                }
            ],
            "recommendations": [
                "å»ºè®®é‡‡ç”¨æ•æ·å¼€å‘æ–¹æ³•ï¼Œåˆ†é˜¶æ®µè¿­ä»£",
                "é‡è§†ä»£ç è´¨é‡å’Œæ–‡æ¡£ç¼–å†™",
                "å®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥å’Œæµ‹è¯•",
                "ä¿æŒä¸å›¢é˜Ÿæˆå‘˜çš„è‰¯å¥½æ²Ÿé€š"
            ]
        }, ensure_ascii=False, indent=2)
    
    def _get_task_enhancement_response(self) -> str:
        """ä»»åŠ¡å¢å¼ºæ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "enhanced_description": "è¿™æ˜¯ä¸€ä¸ªç»è¿‡AIä¼˜åŒ–çš„ä»»åŠ¡æè¿°ã€‚ä»»åŠ¡å·²è¢«ç»†åŒ–ä¸ºæ›´å…·ä½“çš„æ­¥éª¤ï¼ŒåŒ…å«äº†å®æ–½å»ºè®®å’Œæœ€ä½³å®è·µã€‚å»ºè®®é‡‡ç”¨ç³»ç»Ÿæ€§çš„æ–¹æ³•æ¥Completedï¼Œç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½æœ‰æ˜ç¡®çš„ç›®æ ‡å’ŒéªŒæ”¶æ ‡å‡†ã€‚",
            "subtasks": [
                {
                    "title": "å‡†å¤‡é˜¶æ®µ",
                    "description": "æ”¶é›†å¿…è¦çš„èµ„æºå’Œå·¥å…·ï¼Œåˆ¶å®šè¯¦ç»†çš„å®æ–½è®¡åˆ’",
                    "estimated_time": "30åˆ†é’Ÿ"
                },
                {
                    "title": "æ‰§è¡Œé˜¶æ®µ",
                    "description": "æŒ‰ç…§è®¡åˆ’æ‰§è¡Œä¸»è¦å·¥ä½œå†…å®¹ï¼Œæ³¨æ„è´¨é‡æ§åˆ¶",
                    "estimated_time": "2å°æ—¶"
                },
                {
                    "title": "éªŒè¯é˜¶æ®µ",
                    "description": "æ£€æŸ¥å·¥ä½œæˆæœï¼Œç¡®ä¿ç¬¦åˆé¢„æœŸè¦æ±‚",
                    "estimated_time": "30åˆ†é’Ÿ"
                }
            ],
            "estimated_time": "3å°æ—¶",
            "difficulty": "ä¸­ç­‰",
            "implementation_tips": [
                "å»ºè®®åˆ†é˜¶æ®µCompletedï¼Œé¿å…ä¸€æ¬¡æ€§å¤„ç†è¿‡å¤šå†…å®¹",
                "åœ¨Startedå‰ç¡®ä¿æ‰€æœ‰ä¾èµ–æ¡ä»¶éƒ½å·²æ»¡è¶³",
                "å®šæœŸSaveå·¥ä½œè¿›åº¦ï¼Œé¿å…æ„å¤–ä¸¢å¤±",
                "é‡åˆ°é—®é¢˜æ—¶åŠæ—¶å¯»æ±‚å¸®åŠ©æˆ–æŸ¥é˜…æ–‡æ¡£"
            ],
            "resources": [
                {
                    "type": "ğŸ“š æ–‡æ¡£",
                    "name": "æœ€ä½³å®è·µæŒ‡å—",
                    "description": "ç›¸å…³é¢†åŸŸçš„æœ€ä½³å®è·µå’Œç»éªŒæ€»ç»“"
                },
                {
                    "type": "ğŸ› ï¸ å·¥å…·",
                    "name": "å¼€å‘å·¥å…·",
                    "description": "æ¨èä½¿ç”¨çš„å¼€å‘å·¥å…·å’Œç¯å¢ƒ"
                }
            ]
        }, ensure_ascii=False, indent=2)
    
    def _get_task_breakdown_response(self) -> str:
        """ä»»åŠ¡åˆ†è§£æ¨¡æ‹Ÿå“åº”"""
        return json.dumps({
            "breakdown_analysis": {
                "complexity": "ä¸­ç­‰",
                "estimated_total_time": "4-6å°æ—¶",
                "recommended_approach": "åˆ†é˜¶æ®µæ‰§è¡Œ"
            },
            "subtasks": [
                {
                    "title": "éœ€æ±‚åˆ†æ",
                    "description": "åˆ†æå…·ä½“éœ€æ±‚å’Œçº¦æŸæ¡ä»¶",
                    "priority": "high",
                    "estimated_time": "1å°æ—¶"
                },
                {
                    "title": "æ–¹æ¡ˆè®¾è®¡",
                    "description": "è®¾è®¡å®æ–½æ–¹æ¡ˆå’ŒæŠ€æœ¯è·¯çº¿",
                    "priority": "high",
                    "estimated_time": "1.5å°æ—¶"
                },
                {
                    "title": "å…·ä½“å®æ–½",
                    "description": "æŒ‰ç…§æ–¹æ¡ˆè¿›è¡Œå…·ä½“å®æ–½",
                    "priority": "high",
                    "estimated_time": "2-3å°æ—¶"
                },
                {
                    "title": "æµ‹è¯•éªŒè¯",
                    "description": "æµ‹è¯•å®æ–½ç»“æœï¼ŒéªŒè¯æ˜¯å¦ç¬¦åˆè¦æ±‚",
                    "priority": "medium",
                    "estimated_time": "30åˆ†é’Ÿ"
                }
            ]
        }, ensure_ascii=False, indent=2)
    
    def _get_general_response(self) -> str:
        """é€šç”¨æ¨¡æ‹Ÿå“åº”"""
        return "è¿™æ˜¯ä¸€ä¸ªAIç”Ÿæˆçš„å“åº”ã€‚ç”±äºå½“å‰ä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿæ¨¡å¼ï¼Œå®é™…çš„AIåŠŸèƒ½éœ€è¦Configurationæœ‰æ•ˆçš„APIå¯†é’¥ã€‚æ‚¨å¯ä»¥åœ¨ç¯å¢ƒå˜é‡ä¸­SettingsOPENROUTER_API_KEYæ¥å¯ç”¨çœŸå®çš„AIåŠŸèƒ½ã€‚"

# åˆ›å»ºå…¨å±€å®¢æˆ·ç«¯å®ä¾‹
ai_client = OpenRouterClient()

# ä¾¿æ·å‡½æ•°
def get_ai_response(prompt: str, context: str = "") -> AIResponse:
    """è·å–AIå“åº”çš„ä¾¿æ·å‡½æ•°"""
    messages = []
    
    if context:
        messages.append({
            "role": "system",
            "content": context
        })
    
    messages.append({
        "role": "user",
        "content": prompt
    })
    
    return ai_client.chat_completion(messages)

def enhance_task_with_ai(task_title: str, task_description: str = "", additional_context: str = "") -> AIResponse:
    """ä½¿ç”¨AIå¢å¼ºä»»åŠ¡"""
    prompt = f"""
è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡æä¾›AIå¢å¼ºå»ºè®®ï¼š

ä»»åŠ¡æ ‡é¢˜ï¼š{task_title}
ä»»åŠ¡æè¿°ï¼š{task_description or 'æ— '}
è¡¥å……Infoï¼š{additional_context or 'æ— '}

è¯·æä¾›ä»¥ä¸‹å†…å®¹çš„JSONæ ¼å¼å“åº”ï¼š
1. enhanced_description: ä¼˜åŒ–åçš„ä»»åŠ¡æè¿°
2. subtasks: å­ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«titleã€descriptionã€estimated_time
3. estimated_time: æ€»é¢„ä¼°æ—¶é—´
4. difficulty: éš¾åº¦ç­‰çº§ï¼ˆç®€å•/ä¸­ç­‰/å›°éš¾ï¼‰
5. implementation_tips: å®æ–½å»ºè®®åˆ—è¡¨
6. resources: æ¨èèµ„æºåˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«typeã€nameã€description

è¯·ç¡®ä¿å“åº”æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
"""
    
    context = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®ç®¡ç†å’Œä»»åŠ¡è§„åˆ’åŠ©æ‰‹ï¼Œæ“…é•¿å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯ç®¡ç†çš„å­ä»»åŠ¡ï¼Œå¹¶æä¾›å®ç”¨çš„å®æ–½å»ºè®®ã€‚"
    
    return get_ai_response(prompt, context)

def plan_project_with_ai(project_title: str, project_description: str = "", requirements: str = "") -> AIResponse:
    """ä½¿ç”¨AIè¿›è¡Œé¡¹ç›®è§„åˆ’"""
    prompt = f"""
è¯·ä¸ºä»¥ä¸‹é¡¹ç›®æä¾›AIè§„åˆ’å»ºè®®ï¼š

é¡¹ç›®æ ‡é¢˜ï¼š{project_title}
é¡¹ç›®æè¿°ï¼š{project_description or 'æ— '}
å…·ä½“è¦æ±‚ï¼š{requirements or 'æ— '}

è¯·æä¾›ä»¥ä¸‹å†…å®¹çš„JSONæ ¼å¼å“åº”ï¼š
1. project_analysis: é¡¹ç›®åˆ†æï¼ŒåŒ…å«complexityã€estimated_durationã€key_challenges
2. suggested_tasks: å»ºè®®ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«titleã€descriptionã€priorityã€estimated_timeã€dependencies
3. milestones: é‡Œç¨‹ç¢‘åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«nameã€descriptionã€target_date
4. recommendations: å»ºè®®åˆ—è¡¨

è¯·ç¡®ä¿å“åº”æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
"""
    
    context = "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„é¡¹ç›®ç»ç†ï¼Œæ“…é•¿é¡¹ç›®è§„åˆ’ã€ä»»åŠ¡åˆ†è§£å’Œé£é™©è¯„ä¼°ã€‚"
    
    return get_ai_response(prompt, context)